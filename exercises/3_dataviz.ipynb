{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3\n",
    "## Data visualisation\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "How can I readin and visualise data in Python?\n",
    "\n",
    "### Objectives\n",
    "<div class=obj>\n",
    "<ol>\n",
    "    <li>Read data from a file into a program.</li>\n",
    "    <li>Select individual values and subsections from data.</li>\n",
    "    <li>Perform operations on arrays of data.</li>\n",
    "    <li>Plot graphs from data.</li>\n",
    "</ol>\n",
    "    \n",
    "<ul>\n",
    "Revise:\n",
    "    <li>Defining functions;</li>\n",
    "    <li>Storing and accessing data in objects;</li>\n",
    "    <li>Using Python for maths;</li>\n",
    "    <li>Importing libararies.</li>\n",
    "</ul>\n",
    "</div>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Independent coding\n",
    "\n",
    "Readin and visualise data from a large data file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Readin\n",
    "***\n",
    "\n",
    "You can write raw Python code to readin data files, but if coding up our `geo_sin()` function has taught us anything, it should be that we are much better off using a library to do basic work like this for us.\n",
    "\n",
    "A powerful library to use for data readin is `Pandas` - you can find documentation and handy examples __[here](https://pandas.pydata.org/pandas-docs/stable/)__.  As before with NumPy, let's import the package and give it a short name that is convenient for typing out lots of times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can read in a __[wide range of file types](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html)__ with pandas.  One of the simplest file types is a 'comma separated variable' file, which as the name suggests, just uses commas to separate columns of information in a file.  These are otherwise simple text files that you could open in many programs.\n",
    "\n",
    "Let's opon up a very simple data file just to see how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>density</th>\n",
       "      <th>formula</th>\n",
       "      <th>hardness</th>\n",
       "      <th>coolness_factor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>olivine</th>\n",
       "      <td>3.32</td>\n",
       "      <td>Mg2SiO4</td>\n",
       "      <td>6.5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plagioclase</th>\n",
       "      <td>2.70</td>\n",
       "      <td>NaAlSi3O8</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clinopyroxene</th>\n",
       "      <td>3.30</td>\n",
       "      <td>Mg2Si2O6</td>\n",
       "      <td>5.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quartz</th>\n",
       "      <td>2.65</td>\n",
       "      <td>SiO2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               density    formula  hardness  coolness_factor\n",
       "olivine           3.32    Mg2SiO4       6.5               10\n",
       "plagioclase       2.70  NaAlSi3O8       6.0                3\n",
       "clinopyroxene     3.30   Mg2Si2O6       5.5                6\n",
       "quartz            2.65       SiO2       7.0                0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('./data/mineral_top_trumps.csv', header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If it has worked, a table should have appeared above.\n",
    "\n",
    "How it worked:\n",
    "- We are calling the `read_csv()` method from within pandas.\n",
    "- The first argument to `read_csv()` is giving the location of the data file.\n",
    "- The third argument is saying that there is a header (i.e., column names) at the first row (remember that Python starts counting from zero).\n",
    "- The fourth argument is saying that there is an 'index column', i.e., the data file contains a column of entries we want to consider the names of each row.\n",
    "\n",
    "It is not necessary to have either row names or column names, in which case they will just be assigned numerical values starting from 0.  But, how do we know whether the file has a header or row names before loading it in? \n",
    ">Always look at a data file before trying to read it in.\n",
    "\n",
    "You could view the data file in excel (if excel will open it), through a simple text editor, through a command-line command like `more`, or through JupyterLab itself.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Select the data you want\n",
    "***\n",
    "\n",
    "### 3.2.1 Columns and rows\n",
    "We can access content from the datafile in a variety of ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first, let's readin our file again, but this time store it in an object, so we don't have to keep reading it in\n",
    "dfm = pd.read_csv('data/mineral_top_trumps.csv', header=0, index_col=0)\n",
    "\n",
    "#let's access some columns\n",
    "# we can do it like this\n",
    "dfm.density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#or like this\n",
    "dfm['formula']\n",
    "\n",
    "#notice how this takes square brackets, like when we select an index from a list \n",
    "# whereas functions have parantheses after them: my_func() vs. my_list[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#or even like this\n",
    "dfm.loc[:,'coolness_factor']\n",
    "\n",
    "#notice that as the dataframe is 2D we need two indexes to specify where we want information from\n",
    "# the first index is rows and the second index is the column\n",
    "# here, by using ':' for rows, we are saying 'include all rows'\n",
    "# and we are using the column header 'coolness_factor' to specify which column we want.\n",
    "# Try playing with these values and seeing what you get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#and even a fourth way!!!\n",
    "dfm.iloc[:,2]\n",
    "\n",
    "#again, we need to indices to access the entire contents of the dataframe.\n",
    "# this time we use '2' to specify the column, which gives is the 3rd column as Python counts from 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look briefly at selecting multiple columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can select multiple columns at once\n",
    "# either by slicing, as we saw with lists earlier\n",
    "print(dfm.iloc[:,0:2])\n",
    "\n",
    "# notice, that as we are used to this does _not_ include the end point (which would be the 'hardness' column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#or we can access columns using their names and using the slicing notation ':'\n",
    "dfm.loc[:,'density' : 'hardness']\n",
    "\n",
    "#...wihch _does_ include the end point of the 'slice'!!\n",
    "# sometimes with code you just have to accept its eccentricities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finally, if you want specific columns you can just include them as a list\n",
    "dfm.loc[:,['coolness_factor', 'density']]\n",
    "\n",
    "#notice, this also allows you to change the order of columns in the table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting rows of data is achieved very similarly to columns.  Here are the different ways of selecting olivine and all the information we have associated with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can use the '.loc[]' method\n",
    "dfm.loc['olivine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#or we can use numerical indices\n",
    "dfm.iloc[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that each time pandas is giving us a little extra information at the bottom of the output: the name of the column and the data type.  \n",
    "\n",
    "- **density** and **hardness** gave data types of `float64`, this is telling us that these are decimal numbers.\n",
    "- **formula** gave data type `object`, these are mixed numbers and letters and will be treated like a `string` by Python (i.e., as some text).\n",
    "- **coolness_factor** gave data type `int64`, this is an integer, Pandas recognised that none of these inputs were decimal: coolness apparently comes in whole units.\n",
    "\n",
    "Although not the focus of this exercise, it is important to understand that every object in Python has a **type**, and that type determines what operations can be performed on it.  \n",
    "\n",
    "To find out what type an object has let's look at our data object, `dfm`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dfm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us `dfm` is a pandas DataFrame, so all the inbuilt functions that you can perform on dataframes are available to us when using that object.  We will look at a few of these in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Selecting data based on the contents of the data frame itself\n",
    "We have now seen how to slice up the contents of data frames to get the information we want.  Howver, that was for a very simple case.  \n",
    "\n",
    "Another common problem is wanting to access elements of a dataframe based on the information contained in the dataframe itself.  Let's look at this with a new dataset that is a little more complex, a list of Icelandic eruptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('data/iceland_eruptions.xls')\n",
    "#pandas can read excel files too!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we all looked at that file before we loaded it in to see what we were dealing with...\n",
    "\n",
    "In case not, pandas has a trick to help us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this will give us the first few rows of the file, including the header\n",
    "# so we get an understanding of what it contains\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of `NaN` values in the file.  This stands for 'not a number', and indicates missing data.  Pandas automatically identifies `NaN` entries if the entry matches a certain syntax (see __[here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)__ for more details).\n",
    "\n",
    "Otherwise, you can see we are dealing with eruptions, some information about those eruptions and geochemical analyses.\n",
    "\n",
    "How much data do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us the number of rows (3385) and columns (15) we have in our data table.\n",
    "\n",
    "But, we can see that many of the eruptions are missing key information (such as a name), and are a bit useless to us.\n",
    "\n",
    "Let's select:\n",
    "- Eruptions with names, &\n",
    "- Eruptions with known volumes, &\n",
    "- Eruptions with a composition listed for every element, &\n",
    "- Eruptions from the Iceland Holocene (age < 12 kyr)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will look closely at the first example, and then work quickly through the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eruptions with names\n",
    "# we can use the .notna() function to identify those entries with names listed\n",
    "# i.e., those that are 'not a NaN'\n",
    "df.Eruption.notna()\n",
    "\n",
    "#this gives a lot of output... You can click on the cell edge to the left to collapse cells that you want to\n",
    "# hide for convenience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we need to use that list of true's and false's to actually select the data\n",
    "# we can do this by passing the big list of true and false back to the dataframe\n",
    "df[df.Eruption.notna()].head()\n",
    "\n",
    "#we used head() again to just keep the output manageable, but you can see we \n",
    "# now just have eruptions with names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Still, this isn't good enough, not all our eruptions have known volumes\n",
    "# we can do the same as before and identify entries which don't have 'NaN' in the volume column\n",
    "# but we now need to combine this with the selection for eruption name\n",
    "# we use the '&' symbol for this i.e., we want eruptions with names _and_ with volumes\n",
    "df[df.Eruption.notna() & df['Volume(km3)'].notna()].head()\n",
    "\n",
    "#note, we had to use ['Volume(km3)'] rather than '.Volume(km3)' because of the parentheses\n",
    "# in the column name.  Object methods, like functions and variables, can't be given names with parentheses \n",
    "# in them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's two of our conditions met, maybe all these eruptions also have chemistry measured? Let's check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first let's store our cleaned up data in a new dataframe\n",
    "df_tidy = df[df.Eruption.notna() & df['Volume(km3)'].notna()]\n",
    "\n",
    "#now, let's look to see if any of the oxides are missing in any of the eruptions\n",
    "print( df_tidy.loc[:,'SiO2':'P2O5'].notna().all(1) )\n",
    "\n",
    "#How this works:\n",
    "# we take df_clean and we say we want to look at all rows, ':', and the major element data columns 'SiO2':'P2O5'\n",
    "# now, we evaluate whether each entry is _not_ a NaN, i.e., we get a True value returned for every non-NaN\n",
    "# now, using '.all()' we ask 'are all entries along the row = True', we specify to look along row by passing '1' to '.all()'\n",
    "\n",
    "# Every False value you see below is an eruption that doesn't have complete chemistry supplied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finally, we take the list of true-false values and pass them back to df_clean to select only complete chemical entries\n",
    "df_Vtidy = df_tidy[df_tidy.loc[:,'SiO2':'P2O5'].notna().all(1)]\n",
    "\n",
    "#Look inside df_tidy at the row locations recording 'False' above\n",
    "# to convince yourself that we really have found the entries with partial data\n",
    "# Hint: use df_tidy.loc to do this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we want to remove any eruptions older than 12 kyr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's first look at the range of ages present to see whether there even are any old ones\n",
    "df_Vtidy.age.describe()\n",
    "\n",
    "#...yes there are!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can filter numeric data very easily using standard comparison operators\n",
    "# we should also make sure again that there are no NaN values in the ages\n",
    "df_best = df_Vtidy[(df_Vtidy.age < 12000) & (df_Vtidy.age.notna())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wonder how much data we are left with now? We started off with 3385 data entries..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'...and ended up with {df_best.shape[0]} not too bad!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Operating on data frames\n",
    "***\n",
    "\n",
    "As we have seen hints of above, Pandas dataframes have a huge amount of inbuilt functionality (see just how much __[here](https://pandas.pydata.org/pandas-docs/stable/reference/frame.html)__).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's answer the question we have all been waiting for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('How cool is our mineral collection?')\n",
    "\n",
    "#sum all the entries in the coolness column\n",
    "total_coolness = dfm.coolness_factor.sum()\n",
    "\n",
    "print(f'This cool: {total_coolness}!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, Pandas can perform some simple maths for us on the data table.\n",
    "\n",
    "Let's go back to the Icelandic eruption data and pull some statistics out of it, just using Pandas' built in functions.  (Note, that we could use NumPy functions to perform similar calculations, or even write our own)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first, I want to rename 'Volume(km3)' to something easier to type\n",
    "df_best.rename({'Volume(km3)':'volume'}, axis='columns', inplace = True)\n",
    "# the 'inplace = True' here is very important, it is telling Pandas that we want to do this renaming on\n",
    "# this very dataframe, rather than creating a new dataframe with the updated name, which would be its default behaviour\n",
    "\n",
    "#Now, let's see what the average eruption volume is on Iceland\n",
    "df_best.volume.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how about comparing the eruption volumes of lavas with low MgO (<= 5wt%) and with high MgO (> 5wt%)\n",
    "# we can use the conditional statements we learnt about previously to index the dataframe\n",
    "vLmg = df_best[df_best.MgO <=7.50].volume.mean()\n",
    "\n",
    "vHmg = df_best[df_best.MgO >7.50].volume.mean()\n",
    "\n",
    "#let's print the output and use .format to reduce the output precision to something sensible\n",
    "# it's surprisingly hard to measure the volume of volcanoes!\n",
    "print(f'The average volume of high MgO eruptions is {vHmg:.2f} (km3)')\n",
    "\n",
    "print(f'The average volume of low MgO eruptions is {vLmg:.2f} (km3)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An interesting result!  The high MgO eruptions look smaller in eruptive volume than the low MgO eruptions. We should investigate whether this difference is significant by comparing the standard deviations of the two populations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first if we are going to keep investigating these two subdatasets, it might be easier to create \n",
    "# two knew dataframes\n",
    "dfLmg = df_best[df_best.MgO <=7.50]\n",
    "dfHmg = df_best[df_best.MgO >7.50]\n",
    "\n",
    "vstdHmg = dfLmg.volume.std()\n",
    "vstdLmg = dfHmg.volume.std()\n",
    "\n",
    "print(f'The average volume of high MgO eruptions is {vHmg:.2f} +/- {vstdHmg:.2f} (km3)\\n')\n",
    "print(f'The average volume of low MgO eruptions is {vLmg:.2f} +/- {vstdLmg:.2f} (km3)\\n')\n",
    "\n",
    "\n",
    "#let's write a simple if statement to tell us the outcome of comparing these two values\n",
    "# we're looking for the two mean volumes from each dataset to _not_ overlap within error\n",
    "# in order for there to be a significant difference\n",
    "\n",
    "#even though we know vLmg > vHmg, sometimes its good to write code that is robust to changes in the input\n",
    "# like if we added more data\n",
    "sad_outcome = ':( I\\'m not going to be able to write a paper from this.'\n",
    "good_outcome = 'Yay! Better get writing the Nature paper.'\n",
    "if vLmg > vHmg:\n",
    "    if (vLmg - vstdLmg < vHmg) or (vLmg - vstdLmg < vHmg + vstdHmg):\n",
    "        print(sad_outcome)\n",
    "    else:\n",
    "        print(good_outcome)\n",
    "if vHmg > vLmg:\n",
    "    if (vHmg - vstdHmg < vLmg) or (vHmg - vstdHmg < vLmg + vstdLmg):\n",
    "        print(sad_outcome)\n",
    "    else:\n",
    "        print(good_outcome)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Have a go!\n",
    "\n",
    "These are just some trivial examples of what Pandas can do to analyse data.  Look in the __[Pandas documentation](https://pandas.pydata.org/pandas-docs/stable/reference/frame.html)__ to find more examples and test them out on this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Plotting<a id=sec14></a>\n",
    "***\n",
    "\n",
    "To plot data we are going to need to load a new library, `matplotlib`, specifically the plotting tools it contains, `pyplot`, which we access using the 'dot' syntax after `matplotlib`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#again, we want to give our imported library a simple name that isn't too onerous to type out lots\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, there are a number of ways of producing plots with `matplotlib.pyplot`, offering different degrees of control and customisation options.  First, let's use the simplest method to plot some of the classic igneous differentiation diagrams from our dataset of Icelandic eruptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#x data goes in first, followed by y data\n",
    "plt.scatter(df_best.MgO, df_best.Na2O);\n",
    "\n",
    "#note: I am putting ';' after the command to stop the object reference being printed\n",
    "# try removing the semi-colon and seeing what gets printed\n",
    "# although it seems useless, this output can be useful as we will see in a subsequent plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's now add some label names to our plot\n",
    "# also, I'm not sure about these default colors, so let's change those\n",
    "plt.scatter(df_best.MgO, df_best.Na2O,\n",
    "            c='None',           #set color of symbol center, in this case an empty symbol\n",
    "            edgecolor='black',  #set the edge color to black\n",
    "            linewidths=0.2);    #make the line width thin, this helps us see overlapping data points\n",
    "\n",
    "# wt% = weight %, i.e., it is the oxide abundance by weight in the sample\n",
    "plt.xlabel('MgO (wt%)')\n",
    "\n",
    "#now, the y-label is a bit trickier, as really we want to write Na2O with a subscript on the 2\n",
    "# we can do this using syntax from the LaTeX document writing language.  You may have heard of this\n",
    "# and its a great option for writing your pt3 report.  However, for now, don't worry about the detailed syntax\n",
    "plt.ylabel(r'Na $f{_2}$O (wt%)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">As a reminder: Basalts start with high MgO and then evolve during crystallisation to low MgO as phases like olivine and clinopyroxene crystallise (you can see why these decrease MgO from their chemical formulae that we looked at above).  Now, whilst MgO is decreasing Na<sub>2</sub>O increases because it is _not_ incorporated into crystallising phases.\n",
    "\n",
    "What would be interesting to know is whether the large volume eruptions are any more likely to lie at a particular point along this igneous differentiation trend.  To do this let's colour the plot symbols by the eruption volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#Now add color to the points, and make the symbols a bit larger so we can see them.\n",
    "plt.scatter(df_best.MgO, df_best.Na2O, c=df_best.volume);\n",
    "\n",
    "plt.xlabel('MgO (wt%)')\n",
    "plt.ylabel(r'Na${_2}$O (wt%)')\n",
    "\n",
    "#we should also add a colour bar\n",
    "# note: in most (all?) programming languages spelling is American English!\n",
    "plt.colorbar(label=r'Volume (km$^{3}$)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, it does look like large eruptions cluster at a very narrow range of MgO contents.  I wonder if anyone has published on this...\n",
    "\n",
    "It would also be interesting to see how eruption volumes change through time let's try and put this as another panel on the same figure.  For this we are going to need to set up our plot in a slightly different way and we are going to want to plot a histogram, using `ax.hist(...)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first, let's create figure and axis obejcts, using 'subplots' to say that \n",
    "# we are going to be creating more than a single plot in this figure '.subplots(2)'\n",
    "# says it is going to be two figures\n",
    "fg, ax = plt.subplots(2)\n",
    "\n",
    "#now we can plot like before, but with slightly different commands\n",
    "# the plotting is actually a method contained by the axes object we just created\n",
    "# as we have created more than one plot inside this figure, the axes need to be accessed\n",
    "# using [] and indexes like we are used to for lists\n",
    "im = ax[0].scatter(df_best.MgO, df_best.Na2O, c=df_best.volume);\n",
    "\n",
    "#remember how previously we placed a ';' after some of the commands to stop them printing \n",
    "# out the reference to the object?  Well, now we need to save that information so that we can \n",
    "# refer to the specific plotting instance created by our command above 'ax[0].scatter(...'\n",
    "# that is why the command is starts 'im = ...'.\n",
    "# we will use this to place a color bar on the plot\n",
    "fg.colorbar(im, ax=ax[0], label=r'Volume (km$^\\mathsf{3}$)')\n",
    "\n",
    "#we can set it up just like before, the commands are just a little different but self explanatory\n",
    "ax[0].set_xlabel('MgO (wt%)')\n",
    "ax[0].set_ylabel(r'Na${_2}$O (wt%)')\n",
    "fg.set_size_inches(10, 10.5, forward=True)\n",
    "#setting the physical size of the plot here so it is big enough to see\n",
    "\n",
    "#now let's plot onto the bottom panel\n",
    "# notice that we can do maths on the input if we want to transform units, for example.\n",
    "# We also need to select only unique eruptions, i.e,. we don't want to count an eruption\n",
    "# multiple times just because there are multiple chemical analyses of it\n",
    "# for this we use '.groupby(...)', i.e., 'group the data entries by...' and we need to then add\n",
    "# '.mean()' so that Pandas knows what to do with the repeated information for each entry (in this\n",
    "# case to take the mean)\n",
    "df_tmp = df_best.groupby('Eruption').mean()\n",
    "\n",
    "#now we are ready to plot our histogram\n",
    "n, bins, patches = ax[1].hist(df_tmp.age/1e3, weights=df_tmp.volume)\n",
    "\n",
    "ax[1].set_xlabel('Age (kyr)')\n",
    "ax[1].set_ylabel(r'Volume (km$^{3}$)')\n",
    "\n",
    "#we need to call this to automatically move the axes around so there is \n",
    "# space for the labels.  Try commenting it out and replotting the figure\n",
    "# to see what happens without it\n",
    "fg.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, it looks like we got a lot of volume post-deglaciation at 12 kyr, and then there are some large eruptions more recently.  However, 100 km<sup>3</sup> looks a little large... We should probably worry about how good the age information we put in is, and read some of the __[relevant literature](https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2001GC000282)__ first!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Independent coding\n",
    "***\n",
    "\n",
    "<div class=obj>\n",
    "    <b>Aim:</b> To readin and visualise the data from a large data file.\n",
    "</div>\n",
    "\n",
    "<p></p>\n",
    "\n",
    "There are a few classic plots in exoplanetary science, which both highlight the discoveries of the field to date, and the shortcomings of our detection methods.  The dataset we will use to explore these is taken from __[exoplanets.eu](http://exoplanet.eu)__.\n",
    "\n",
    "### Mass-radius\n",
    "The first of these classic diagrams is the 'planet radius' vs. 'planet mass' diagram.  This relationship encodes a fundamental property of a planet: its average density.  Whilst for Earth this 5.51 g/cm<sup>3</sup>, for Saturn it is 0.687 g/cm<sup>3</sup>, less dense than water!  Let's see what this relationship looks like for exoplanets, do they look more like Earth or more like Saturn?\n",
    "\n",
    "You should:\n",
    "1. Create a new notebook, called `Exercise2_solution`.<br>\n",
    "2. Readin the data file `exoplanet.eu_catalog.csv`, it is inside the `data` folder.<br>\n",
    "3. Filter the datafile for:<br>\n",
    "  - Planets that have a status of 'confirmed' (i.e., we know are real planets and not a data artefact)<br>\n",
    "  - Planets that have a mass recorded<br>\n",
    "  - Planets that have a radius measurement<br>\n",
    "4. Plot the data, labelling the axes<br>\n",
    "5. Rescale the axes to best display the data in the region we are interested in (1-20 Earth mass planets)<br>\n",
    "\n",
    "_Hint 1: 1 Jupiter mass = 317.8 Earth masses, 1 Jupiter Radius = 11.2 Earth radii.  The planet masses are in Jupiter masses and Jupiter radii._\n",
    "\n",
    "_Hint 2:_ There are a lot of columns in the datafile we are not interested in.  You can use `df.keys()` to list the names of the columns as a simple list.\n",
    "\n",
    "This gives you the basic plot, to go further consider,\n",
    "5. using a log x axis (here is __[one solution](https://stackoverflow.com/questions/773814/plot-logarithmic-axes-with-matplotlib-in-python)__) to display more of the data in one go;\n",
    "6. coloring the points by their 'calculated temperature', this is their __[equilibrium temperature](https://en.wikipedia.org/wiki/Planetary_equilibrium_temperature)__, which you might recall from the climate course;\n",
    "7. plotting on lines that show the mass-radius relationship for pure Fe, pure MgSiO<sub>3</sub>, and pure water.  The equations for these relationships we take from __[Seager et al. (2007)](https://iopscience.iop.org/article/10.1086/521346)__:\n",
    "\\begin{equation}\n",
    "\\log_{10}R_s = k_1 + \\frac{1}{3}\\log_{10}(M_s) - k_2M_s^{k_3},\n",
    "\\end{equation}\n",
    "<p></p>\n",
    "where $R_s$ is the scaled radius $R_s = \\dfrac{R}{R_1}$, $M_s$ is the scaled mass $M_s = \\dfrac{M}{M_1}$, and $k_1$, $k_2$ and $k_3$ are constants.\n",
    "\n",
    "|Material|$M_1$|$R_1$|$k_1$|$k_2$|$k_3$|\n",
    "|--------|-----|-----|-----|-----|-----|\n",
    "|Fe      | 5.80 | 2.52 | 􏰄-0.209490 | 0.0804 | 0.394\n",
    "|MgSiO$_\\mathsf{3}$ | 10.55 | 3.90 | -0.209594 | 0.0799 | 0.413\n",
    "|H$\\mathsf{_2}$O (ice) | 5.52 | 4.43 | -0.209396 | 0.0807 | 0.375"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Period-radius\n",
    "\n",
    "This is an important visualisation of the exoplanet catalogue for emphasising the strong biases it contains.\n",
    "\n",
    "For this plot:\n",
    "1. Add to your existing Exercise2_solution notebook.\n",
    "1. Filter the data starting from the freshly loaded data, identifying planets with:\n",
    "    - Period\n",
    "    - Radius\n",
    "1. Plot the data, label the axes, use logarithmic x and y axes.\n",
    "1. Color the data points by detection method (use the 'detection_type' column), you will have to firstlook at the contents.\n",
    "\n",
    "What are the biases you can identify?\n",
    "\n",
    "_Hint 1: The orbital period in the dataset is in days_\n",
    "\n",
    "_Hint 2: The detection types to focus on are: transit, radial velocity and direct imaging.  You can see what unique entries there are in a pandas dataframe's columns by using `df.column_name.unique()`_.\n",
    "\n",
    "_Hint 2: It might help to plot on the location of the solar system planets._\n",
    "\n",
    "|Planet|Radius (km)|Period (days)| Mass (x10<sup>23</sup>kg) |\n",
    "|------|-----------|-----------|-------------|\n",
    "|Mercury | 2440 | 88     | 3.285 |\n",
    "|Venus   | 6051 | 225    | 48.67 |\n",
    "|Earth   | 6371 | 365    | 59.72 |\n",
    "|Mars    | 3390 | 687    | 6.39  |\n",
    "|Jupiter | 69911 | 4329  | 18980 |\n",
    "|Saturn  | 58232 | 10752 | 5683  |\n",
    "|Uranus  | 25362 | 30660 | 868.1 |\n",
    "|Neptune | 24622 | 60225 | 1024  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot optimisation\n",
    "\n",
    "Now you have the basics that will allow you tackle the plotting exercise here.  Remember, there are many many ways of producing plots in Python and an even greater number of aesthetic 'optimisations' to choose from.  As you try and get more control over the appearance of your plots you will have to delve deeper into the specific syntax Python (matplotlib) uses for plotting.\n",
    "\n",
    "Extra things to search for (__[try here](https://matplotlib.org/index.html)__) when completing this exercise:\n",
    "- Setting the x and y range of the axes (can you set the range from the data itself?)\n",
    "- Controlling the color scheme used (can you get a gray scale? Some more interesting colors __[here](https://matplotlib.org/examples/color/colormaps_reference.html)__)\n",
    "- Can you change the font size on the labels?\n",
    "- Can you add a legend?\n",
    "- Can you add a mass-period panel to your mass-radius plot (_Hint: use `plt.subplots(2)`_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
